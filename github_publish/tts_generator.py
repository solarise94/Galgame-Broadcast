#!/usr/bin/env python3
"""
TTS è¯­éŸ³åˆæˆè„šæœ¬ - å°† Markdown å¯¹è¯è½¬æ¢ä¸ºè¯­éŸ³
æ”¯æŒé˜¿é‡Œäº‘ç™¾ç‚¼ Qwen-TTSã€ç¡…åŸºæµåŠ¨ SiliconFlow TTS (å« IndexTTS2ã€CosyVoice2ã€MOSS-TTSD ç­‰) å’Œ MiniMax Speech

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ä½¿ç”¨æ–¹æ³•:                                                        â•‘
â•‘    python tts_generator.py <markdownæ–‡ä»¶> [é€‰é¡¹]                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  å¸¸ç”¨å‘½ä»¤:                                                        â•‘
â•‘    # ä½¿ç”¨é»˜è®¤é…ç½®ç”Ÿæˆ                                             â•‘
â•‘    python tts_generator.py æ–‡çŒ®è§£è¯»å¯¹è¯æ–‡æ¡ˆ-2.md                  â•‘
â•‘                                                                   â•‘
â•‘    # æŒ‡å®šé…ç½®æ–‡ä»¶                                                 â•‘
â•‘    python tts_generator.py æ–‡çŒ®è§£è¯»å¯¹è¯æ–‡æ¡ˆ-2.md -c config.yaml   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  é…ç½®æ–‡ä»¶ (config.yaml) è¯´æ˜:                                     â•‘
â•‘    â€¢ provider         - TTSæä¾›å•† (qwen/siliconflow/minimax)     â•‘
â•‘    â€¢ api.api_key      - API Key                                  â•‘
â•‘    â€¢ api.model        - TTSæ¨¡å‹ (ä»…éƒ¨åˆ†æä¾›å•†éœ€è¦)               â•‘
â•‘    â€¢ voices.male      - ç”·å£°éŸ³è‰²                                 â•‘
â•‘    â€¢ voices.female    - å¥³å£°éŸ³è‰²                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  è¾“å‡ºæ–‡ä»¶:                                                        â•‘
â•‘    â€¢ dialogue_001_male.wav, dialogue_002_female.wav...           â•‘
â•‘    â€¢ dialogue_complete.wav (åˆå¹¶åçš„å®Œæ•´éŸ³é¢‘)                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import re
import yaml
import time
import uuid
import requests
import base64
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod
import wave
import struct
import json


@dataclass
class DialogueLine:
    """å¯¹è¯è¡Œæ•°æ®ç»“æ„"""
    speaker: str  # 'male' æˆ– 'female'
    text: str
    index: int
    mood: str = "gentle"  # æƒ…ç»ª: gentle, happy, confident, expectant, confused, shocked, angry, sad, resigned


class BaseTTSClient(ABC):
    """TTS API å®¢æˆ·ç«¯æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def synthesize(self, text: str, voice_config: Dict, output_path: str) -> bool:
        """åˆæˆå•æ®µè¯­éŸ³"""
        pass


class QwenTTSClient(BaseTTSClient):
    """é˜¿é‡Œäº‘ç™¾ç‚¼ Qwen TTS API å®¢æˆ·ç«¯"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.api_key = config['api']['api_key']
        self.model = config['api']['model']
        self.base_url = config['api']['base_url']
        
        # æ£€æŸ¥ API Key
        if self.api_key == "YOUR_API_KEY_HERE" or not self.api_key:
            raise ValueError("è¯·åœ¨ config.yaml ä¸­è®¾ç½®æœ‰æ•ˆçš„ API Key")
    
    def synthesize(self, text: str, voice_config: Dict, output_path: str) -> bool:
        """
        åˆæˆå•æ®µè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice_config: éŸ³è‰²é…ç½®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/services/aigc/multimodal-generation/generation"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "input": {
                "text": text,
                "voice": voice_config['voice'],
                "language_type": voice_config.get('language_type', 'Chinese')
            }
        }
        
        # å¦‚æœæ˜¯æŒ‡ä»¤æ§åˆ¶æ¨¡å‹ï¼Œæ·»åŠ æŒ‡ä»¤
        if 'instructions' in voice_config and 'instruct' in self.model:
            payload['input']['instructions'] = voice_config['instructions']
            payload['input']['optimize_instructions'] = voice_config.get('optimize_instructions', True)
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šè°ƒç”¨ API è·å–éŸ³é¢‘ URL
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            
            # è§£æå“åº”è·å–éŸ³é¢‘ URL
            if 'output' in result and 'audio' in result['output']:
                audio_info = result['output']['audio']
                
                # ä¼˜å…ˆä» URL ä¸‹è½½éŸ³é¢‘
                if isinstance(audio_info, dict) and 'url' in audio_info and audio_info['url']:
                    audio_url = audio_info['url']
                    # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
                    audio_response = requests.get(audio_url, timeout=60)
                    audio_response.raise_for_status()
                    
                    with open(output_path, 'wb') as f:
                        f.write(audio_response.content)
                    return True
                
                # å¦‚æœ URL ä¸å¯ç”¨ï¼Œå°è¯• base64 æ•°æ®
                elif isinstance(audio_info, dict) and 'data' in audio_info and audio_info['data']:
                    audio_bytes = base64.b64decode(audio_info['data'])
                    with open(output_path, 'wb') as f:
                        f.write(audio_bytes)
                    return True
                else:
                    print(f"è­¦å‘Š: æ— æ³•è·å–éŸ³é¢‘æ•°æ®")
                    return False
            else:
                print(f"API å“åº”å¼‚å¸¸: {result}")
                return False
                
        except requests.exceptions.RequestException as e:
            print(f"API è¯·æ±‚å¤±è´¥: {e}")
            return False
        except Exception as e:
            print(f"åˆæˆå¤±è´¥: {e}")
            return False
    
    def synthesize_streaming(self, text: str, voice_config: Dict, output_path: str) -> bool:
        """
        æµå¼åˆæˆè¯­éŸ³ï¼ˆé€‚ç”¨äºé•¿æ–‡æœ¬ï¼‰
        """
        url = f"{self.base_url}/services/aigc/multimodal-generation/generation"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "input": {
                "text": text,
                "voice": voice_config['voice'],
                "language_type": voice_config.get('language_type', 'Chinese')
            },
            "stream": True
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload, stream=True, timeout=120)
            response.raise_for_status()
            
            audio_chunks = []
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if 'output' in data and 'audio' in data['output']:
                            audio_chunk = base64.b64decode(data['output']['audio'])
                            audio_chunks.append(audio_chunk)
                    except:
                        pass
            
            if audio_chunks:
                with open(output_path, 'wb') as f:
                    for chunk in audio_chunks:
                        f.write(chunk)
                return True
            return False
            
        except Exception as e:
            print(f"æµå¼åˆæˆå¤±è´¥: {e}")
            return False


class MiniMaxTTSClient(BaseTTSClient):
    """MiniMax Speech TTS API å®¢æˆ·ç«¯
    
    æ”¯æŒæ¨¡å‹:
    - speech-2.6-hd (é«˜æ¸…è¯­éŸ³åˆæˆ)
    - speech-2.6-turbo (å¿«é€Ÿè¯­éŸ³åˆæˆ)
    - speech-02-hd / speech-02-turbo
    - speech-01-hd / speech-01-turbo
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.api_key = config['api']['api_key']
        self.model = config['api'].get('model', 'speech-2.6-hd')
        self.base_url = config['api'].get('base_url', 'https://api.minimax.chat')
        self.group_id = config['api'].get('group_id', '')
        
        # æ£€æŸ¥ API Key
        if self.api_key == "YOUR_API_KEY_HERE" or not self.api_key:
            raise ValueError("è¯·åœ¨ config.yaml ä¸­è®¾ç½®æœ‰æ•ˆçš„ API Key")
        
        # æ£€æŸ¥ Group ID (MiniMax éœ€è¦)
        if not self.group_id:
            print("è­¦å‘Š: æœªè®¾ç½® Group IDï¼ŒMiniMax API å¯èƒ½éœ€è¦ Group ID")
    
    def synthesize(self, text: str, voice_config: Dict, output_path: str) -> bool:
        """
        åˆæˆå•æ®µè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice_config: éŸ³è‰²é…ç½®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # æ„å»º API URL
        url = f"{self.base_url}/v1/t2a_v2"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ„å»º voice_setting
        voice_setting = {
            "voice_id": voice_config.get('voice_id', 'Chinese (Mandarin)_Reliable_Executive'),
            "speed": voice_config.get('speed', 1.0),
            "vol": voice_config.get('vol', 1.0),
            "pitch": voice_config.get('pitch', 0)
        }
        
        # æ·»åŠ  emotion å‚æ•°ï¼ˆå¦‚æœé…ç½®ä¸­æœ‰ï¼‰
        if 'emotion' in voice_config:
            voice_setting['emotion'] = voice_config['emotion']
        
        # æ„å»ºè¯·æ±‚ä½“
        payload = {
            "model": self.model,
            "text": text,
            "stream": False,
            "voice_setting": voice_setting,
            "audio_setting": {
                "sample_rate": voice_config.get('sample_rate', 32000),
                "bitrate": voice_config.get('bitrate', 128000),
                "format": voice_config.get('format', 'mp3'),
                "channel": voice_config.get('channel', 1)
            }
        }
        
        # å¯é€‰å‚æ•°
        if 'language_boost' in voice_config:
            payload['language_boost'] = voice_config['language_boost']
        
        if 'pronunciation_dict' in voice_config:
            payload['pronunciation_dict'] = voice_config['pronunciation_dict']
        
        if 'voice_modify' in voice_config:
            payload['voice_modify'] = voice_config['voice_modify']
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=120)
            response.raise_for_status()
            
            result = response.json()
            
            # è§£æå“åº”è·å–éŸ³é¢‘æ•°æ®
            if 'data' in result and 'audio' in result['data']:
                audio_hex = result['data']['audio']
                # ç§»é™¤å¯èƒ½çš„ 0x å‰ç¼€
                if audio_hex.startswith('0x'):
                    audio_hex = audio_hex[2:]
                audio_bytes = bytes.fromhex(audio_hex)
                
                with open(output_path, 'wb') as f:
                    f.write(audio_bytes)
                return True
            else:
                # æ£€æŸ¥é”™è¯¯ä¿¡æ¯
                if 'base_resp' in result and result['base_resp'].get('status_code') != 0:
                    error_msg = result['base_resp'].get('status_msg', 'Unknown error')
                    # è¯†åˆ« rate limit é”™è¯¯
                    if 'rate limit' in error_msg.lower() or 'rpm' in error_msg.lower():
                        print(f"API é”™è¯¯: {error_msg} (éœ€è¦å¢åŠ  rate_limit.delay)")
                    else:
                        print(f"API é”™è¯¯: {error_msg}")
                else:
                    print(f"API å“åº”å¼‚å¸¸: {result}")
                return False
                
        except requests.exceptions.RequestException as e:
            print(f"API è¯·æ±‚å¤±è´¥: {e}")
            return False
        except Exception as e:
            print(f"åˆæˆå¤±è´¥: {e}")
            return False
    
    def synthesize_streaming(self, text: str, voice_config: Dict, output_path: str) -> bool:
        """
        æµå¼åˆæˆè¯­éŸ³ï¼ˆé€‚ç”¨äºé•¿æ–‡æœ¬ï¼‰
        """
        url = f"{self.base_url}/v1/t2a_v2"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ„å»º voice_setting
        voice_setting = {
            "voice_id": voice_config.get('voice_id', 'Chinese (Mandarin)_Reliable_Executive'),
            "speed": voice_config.get('speed', 1.0),
            "vol": voice_config.get('vol', 1.0),
            "pitch": voice_config.get('pitch', 0)
        }
        
        # æ·»åŠ  emotion å‚æ•°ï¼ˆå¦‚æœé…ç½®ä¸­æœ‰ï¼‰
        if 'emotion' in voice_config:
            voice_setting['emotion'] = voice_config['emotion']
        
        payload = {
            "model": self.model,
            "text": text,
            "stream": True,
            "voice_setting": voice_setting,
            "audio_setting": {
                "sample_rate": voice_config.get('sample_rate', 32000),
                "bitrate": voice_config.get('bitrate', 128000),
                "format": voice_config.get('format', 'mp3'),
                "channel": voice_config.get('channel', 1)
            }
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload, stream=True, timeout=120)
            response.raise_for_status()
            
            audio_chunks = []
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if 'data' in data and 'audio' in data['data']:
                            audio_hex = data['data']['audio']
                            if audio_hex.startswith('0x'):
                                audio_hex = audio_hex[2:]
                            audio_bytes = bytes.fromhex(audio_hex)
                            audio_chunks.append(audio_bytes)
                    except:
                        pass
            
            if audio_chunks:
                with open(output_path, 'wb') as f:
                    for chunk in audio_chunks:
                        f.write(chunk)
                return True
            return False
            
        except Exception as e:
            print(f"æµå¼åˆæˆå¤±è´¥: {e}")
            return False


class SiliconFlowTTSClient(BaseTTSClient):
    """ç¡…åŸºæµåŠ¨ SiliconFlow TTS API å®¢æˆ·ç«¯
    
    æ”¯æŒæ¨¡å‹:
    - IndexTeam/IndexTTS-2 (IndexTTS2, Bç«™å¼€æº)
      * æ”¯æŒæƒ…ç»ªæ§åˆ¶: emo_vector (Neutral, Happy, Sad, Angry, Fearful, Disgusted, Surprised)
      * æ”¯æŒæƒ…æ„Ÿå¼ºåº¦: emo_alpha (0.0 ~ 1.0)
      * æ”¯æŒæƒ…æ„Ÿå‚è€ƒéŸ³é¢‘: emo_audio_prompt
    - FunAudioLLM/CosyVoice2-0.5B (é˜¿é‡ŒCosyVoice)
    - fnlp/MOSS-TTSD-v0.5 (å¤æ—¦å¤§å­¦MOSSå¯¹è¯TTS)
    """
    
    # IndexTTS2 æ”¯æŒçš„æƒ…ç»ªå‘é‡
    INDEXTTS_EMOTIONS = ['Neutral', 'Happy', 'Sad', 'Angry', 'Fearful', 'Disgusted', 'Surprised']
    
    # æˆ‘ä»¬çš„æƒ…ç»ª -> IndexTTS2 æƒ…ç»ªæ˜ å°„
    MOOD_TO_INDEXTTS = {
        'gentle': 'Neutral',
        'happy': 'Happy',
        'confident': 'Neutral',
        'expectant': 'Happy',
        'confused': 'Surprised',
        'shocked': 'Surprised',
        'angry': 'Angry',
        'sad': 'Sad',
        'resigned': 'Sad',
    }
    
    def __init__(self, config: Dict):
        self.config = config
        self.api_key = config['api']['api_key']
        self.model = config['api'].get('model', 'IndexTeam/IndexTTS-2')
        self.base_url = config['api']['base_url']
        
        # æ£€æŸ¥ API Key
        if self.api_key == "YOUR_API_KEY_HERE" or not self.api_key:
            raise ValueError("è¯·åœ¨ config.yaml ä¸­è®¾ç½®æœ‰æ•ˆçš„ API Key")
        
        # æ£€æµ‹æ˜¯å¦ä¸º MOSS-TTSD æ¨¡å‹
        self.is_moss_model = 'MOSS-TTSD' in self.model
        
        # æ£€æµ‹æ˜¯å¦ä¸º IndexTTS2 æ¨¡å‹
        self.is_indextts_model = 'IndexTTS' in self.model
    
    def synthesize(self, text: str, voice_config: Dict, output_path: str) -> bool:
        """
        åˆæˆå•æ®µè¯­éŸ³ (OpenAI å…¼å®¹æ¥å£)
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice_config: éŸ³è‰²é…ç½®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/v1/audio/speech"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ„å»ºéŸ³è‰²æ ‡è¯†
        voice = voice_config.get('voice', '')
        if voice and not voice.startswith(self.model):
            # å¦‚æœä¸æ˜¯å®Œæ•´è·¯å¾„ï¼Œæ·»åŠ æ¨¡å‹å‰ç¼€
            voice = f"{self.model}:{voice}"
        
        # åŸºç¡€è¯·æ±‚ä½“
        payload = {
            "model": self.model,
            "input": text,
            "voice": voice,
            "response_format": voice_config.get('response_format', 'wav'),
        }
        
        # å¯é€‰å‚æ•°
        if 'speed' in voice_config:
            payload['speed'] = voice_config['speed']
        
        if 'gain' in voice_config:
            payload['gain'] = voice_config['gain']
        
        if 'sample_rate' in voice_config:
            payload['sample_rate'] = voice_config['sample_rate']
        
        # åŠ¨æ€éŸ³è‰²/å‚è€ƒéŸ³é¢‘ (ç”¨äºå£°éŸ³å…‹éš†)
        if 'references' in voice_config:
            payload['references'] = voice_config['references']
        
        # IndexTTS2 æƒ…ç»ªæ§åˆ¶å‚æ•°
        if self.is_indextts_model:
            # emo_vector: æƒ…ç»ªå‘é‡ (Neutral, Happy, Sad, Angry, Fearful, Disgusted, Surprised)
            if 'emo_vector' in voice_config:
                payload['emo_vector'] = voice_config['emo_vector']
            
            # emo_alpha: æƒ…æ„Ÿå¼ºåº¦ (0.0 ~ 1.0, é»˜è®¤ 0.7)
            if 'emo_alpha' in voice_config:
                payload['emo_alpha'] = voice_config['emo_alpha']
            
            # emo_audio_prompt: æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘ (base64 æˆ– URL)
            if 'emo_audio_prompt' in voice_config:
                payload['emo_audio_prompt'] = voice_config['emo_audio_prompt']
            
            # use_emo_text: æ˜¯å¦ä½¿ç”¨æƒ…æ„Ÿæ–‡æœ¬æç¤º
            if 'use_emo_text' in voice_config:
                payload['use_emo_text'] = voice_config['use_emo_text']
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=120)
            response.raise_for_status()
            
            # ç›´æ¥è·å–äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
            if response.content:
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                return True
            else:
                print(f"è­¦å‘Š: å“åº”ä¸­æ²¡æœ‰éŸ³é¢‘æ•°æ®")
                return False
                
        except requests.exceptions.RequestException as e:
            # å°è¯•è§£æé”™è¯¯å“åº”
            try:
                error_data = response.json() if response.text else {}
                error_msg = error_data.get('error', {}).get('message', str(e))
                print(f"API è¯·æ±‚å¤±è´¥: {error_msg}")
            except:
                print(f"API è¯·æ±‚å¤±è´¥: {e}")
            return False
        except Exception as e:
            print(f"åˆæˆå¤±è´¥: {e}")
            return False
    
    def synthesize_dialogue(self, dialogues: List[DialogueLine], voice_config: Dict, output_path: str) -> bool:
        """
        MOSS-TTSD ä¸“ç”¨ï¼šä¸€æ¬¡æ€§åˆæˆåŒäººå¯¹è¯
        
        Args:
            dialogues: å¯¹è¯åˆ—è¡¨
            voice_config: éŸ³è‰²é…ç½® (åŒ…å«ä¸¤ä¸ªè¯´è¯äººçš„ references)
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not self.is_moss_model:
            print("è­¦å‘Š: å½“å‰ä¸æ˜¯ MOSS-TTSD æ¨¡å‹ï¼Œæ— æ³•ä½¿ç”¨å¯¹è¯åˆæˆåŠŸèƒ½")
            return False
        
        url = f"{self.base_url}/v1/audio/speech"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ„å»ºå¸¦ [S1]/[S2] æ ‡ç­¾çš„å¯¹è¯æ–‡æœ¬
        # male -> [S1], female -> [S2]
        dialogue_text = ""
        for dialogue in dialogues:
            speaker_tag = "[S1]" if dialogue.speaker == 'male' else "[S2]"
            dialogue_text += f"{speaker_tag}{dialogue.text}"
        
        print(f"  åˆæˆåŒäººå¯¹è¯ï¼Œå…± {len(dialogues)} è½®å¯¹è¯...")
        print(f"  æ–‡æœ¬é•¿åº¦: {len(dialogue_text)} å­—ç¬¦")
        
        # æ„å»ºè¯·æ±‚ä½“
        payload = {
            "model": self.model,
            "input": dialogue_text,
            "response_format": voice_config.get('response_format', 'wav'),
        }
        
        # MOSS-TTSD éœ€è¦é€šè¿‡ references æŒ‡å®šä¸¤ä¸ªè¯´è¯äººçš„å£°éŸ³
        # è€Œä¸æ˜¯ä½¿ç”¨ voice å­—æ®µ
        if 'references' in voice_config:
            payload['references'] = voice_config['references']
        else:
            # å¦‚æœæ²¡æœ‰æä¾› referencesï¼Œä½¿ç”¨ç³»ç»Ÿé¢„ç½®éŸ³è‰²
            # éœ€è¦æ„å»ºä¸¤ä¸ª references é¡¹
            voice = voice_config.get('voice', 'fnlp/MOSS-TTSD-v0.5:alex')
            # æå–åŸºæœ¬éŸ³è‰²å
            if ':' in voice:
                voice_name = voice.split(':')[-1]
            else:
                voice_name = 'alex'
            
            # ä¸º S1 å’Œ S2 åˆ†é…ä¸åŒéŸ³è‰²ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            male_voices = ['alex', 'benjamin', 'charles', 'david']
            female_voices = ['anna', 'bella', 'claire', 'diana']
            
            # é»˜è®¤ä½¿ç”¨ alex å’Œ anna ä½œä¸º S1 å’Œ S2
            s1_voice = voice_name if voice_name in male_voices else 'alex'
            s2_voice = 'anna'  # é»˜è®¤å¥³å£°
            
            # ä½¿ç”¨é»˜è®¤å‚è€ƒéŸ³é¢‘ URLï¼ˆSiliconFlow æä¾›çš„ç¤ºä¾‹ï¼‰
            payload['references'] = [
                {
                    "audio": f"https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/voice_template/fish_audio-{s1_voice.capitalize()}.mp3",
                    "text": "åœ¨ä¸€æ— æ‰€çŸ¥ä¸­ï¼Œæ¢¦é‡Œçš„ä¸€å¤©ç»“æŸäº†ï¼Œä¸€ä¸ªæ–°çš„è½®å›ä¾¿ä¼šå¼€å§‹"
                },
                {
                    "audio": f"https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/voice_template/fish_audio-{s2_voice.capitalize()}.mp3",
                    "text": "åœ¨ä¸€æ— æ‰€çŸ¥ä¸­ï¼Œæ¢¦é‡Œçš„ä¸€å¤©ç»“æŸäº†ï¼Œä¸€ä¸ªæ–°çš„è½®å›ä¾¿ä¼šå¼€å§‹"
                }
            ]
        
        # å¯é€‰å‚æ•°
        if 'speed' in voice_config:
            payload['speed'] = voice_config['speed']
        
        if 'gain' in voice_config:
            payload['gain'] = voice_config['gain']
        
        if 'max_tokens' in voice_config:
            payload['max_tokens'] = voice_config['max_tokens']
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=180)
            response.raise_for_status()
            
            # ç›´æ¥è·å–äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
            if response.content:
                with open(output_path, 'wb') as f:
                    f.write(response.content)
                print(f"  âœ“ åŒäººå¯¹è¯éŸ³é¢‘å·²ç”Ÿæˆ: {output_path}")
                return True
            else:
                print(f"  âœ— è­¦å‘Š: å“åº”ä¸­æ²¡æœ‰éŸ³é¢‘æ•°æ®")
                return False
                
        except requests.exceptions.RequestException as e:
            try:
                error_data = response.json() if response.text else {}
                error_msg = error_data.get('error', {}).get('message', str(e))
                print(f"  âœ— API è¯·æ±‚å¤±è´¥: {error_msg}")
            except:
                print(f"  âœ— API è¯·æ±‚å¤±è´¥: {e}")
            return False
        except Exception as e:
            print(f"  âœ— åˆæˆå¤±è´¥: {e}")
            return False


class MarkdownParser:
    """Markdown å¯¹è¯æ–‡ä»¶è§£æå™¨"""
    
    # æ”¯æŒçš„æƒ…ç»ªåˆ—è¡¨
    MOODS = ['gentle', 'happy', 'confident', 'expectant', 'confused', 
             'shocked', 'angry', 'sad', 'resigned']
    
    def __init__(self, config: Dict):
        self.config = config
        # æ˜¯å¦å¯ç”¨æƒ…ç»ªåŠŸèƒ½ï¼Œé»˜è®¤å¼€å¯
        self.enable_mood = config.get('mood', {}).get('enable', True)
        # æ˜¯å¦ä½¿ç”¨ Markdown ä¸­çš„æƒ…ç»ªå‚æ•°ï¼Œé»˜è®¤å¼€å¯
        self.use_emotion = config.get('emotion', {}).get('use_emotion', True)
        # é»˜è®¤æƒ…ç»ª
        self.default_emotion = config.get('emotion', {}).get('default_emotion', 'gentle')
    
    def parse(self, file_path: str) -> List[DialogueLine]:
        """
        è§£æ Markdown æ–‡ä»¶ï¼Œæå–å¯¹è¯å†…å®¹
        
        æ ¼å¼ (å¸¦æƒ…ç»ª):
        ### male speaker ###
        ### happy ###
        ### æ–‡æœ¬å†…å®¹ ###
        
        æ ¼å¼ (æ— æƒ…ç»ªï¼Œå‘åå…¼å®¹):
        ### male speaker ###
        ### æ–‡æœ¬å†…å®¹ ###
        """
        dialogues = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æµ‹æ˜¯å¦ä½¿ç”¨æ–°æ ¼å¼ï¼ˆåŒ…å«æƒ…ç»ªæ ‡æ³¨ï¼‰
        # æ–°æ ¼å¼: ### speaker ### \n ### mood ### \n ### text ###
        new_pattern = r'###\s*(male|female)\s*speaker\s*###\s*\n\s*###\s*(\w+)\s*###\s*\n\s*###\s*(.*?)\s*###'
        new_matches = re.findall(new_pattern, content, re.DOTALL)
        
        # æ—§æ ¼å¼: ### speaker ### \n ### text ###
        old_pattern = r'###\s*(male|female)\s*speaker\s*###\s*\n\s*###\s*(.*?)\s*###'
        old_matches = re.findall(old_pattern, content, re.DOTALL)
        
        # å¦‚æœæ–°æ ¼å¼åŒ¹é…æˆåŠŸä¸”æ•°é‡åˆç†ï¼ˆçº¦ä¸ºæ—§æ ¼å¼çš„ä¸€åŠæˆ–æ›´å°‘ï¼Œè¯´æ˜ä¸­é—´æ’å…¥äº†moodè¡Œï¼‰
        if new_matches and len(new_matches) >= len(old_matches) / 2:
            # ä½¿ç”¨æ–°æ ¼å¼è§£æ
            for idx, (speaker, mood, text) in enumerate(new_matches, 1):
                # éªŒè¯æƒ…ç»ªæ˜¯å¦æœ‰æ•ˆ
                mood = mood.lower()
                if mood not in self.MOODS:
                    mood = self.default_emotion  # ä½¿ç”¨é»˜è®¤æƒ…ç»ª
                
                # å¦‚æœé…ç½®ä¸ºä¸ä½¿ç”¨æƒ…ç»ªå‚æ•°ï¼Œåˆ™ä½¿ç”¨é»˜è®¤æƒ…ç»ª
                if not self.use_emotion:
                    mood = self.default_emotion
                
                text = self._clean_text(text)
                if text:
                    dialogues.append(DialogueLine(
                        speaker=speaker.lower(),
                        text=text,
                        index=idx,
                        mood=mood
                    ))
        else:
            # ä½¿ç”¨æ—§æ ¼å¼è§£æ
            default_mood = self.default_emotion if not self.use_emotion else "gentle"
            for idx, (speaker, text) in enumerate(old_matches, 1):
                text = self._clean_text(text)
                if text:
                    dialogues.append(DialogueLine(
                        speaker=speaker.lower(),
                        text=text,
                        index=idx,
                        mood=default_mood
                    ))
        
        return dialogues
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†å’Œé¢„å¤„ç†æ–‡æœ¬"""
        # ç§»é™¤æ¢è¡Œç¬¦
        text = text.replace('\n', ' ')
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text).strip()
        
        # ç§»é™¤æ‹¬å·å†…å®¹ï¼ˆå¦‚: ï¼ˆæ‰“æ–­ï¼‰ï¼‰
        if self.config['text_processing'].get('remove_parentheses', True):
            text = re.sub(r'[ï¼ˆ(][^ï¼‰)]+[ï¼‰)]', '', text)
        
        # æ›¿æ¢ Figure X ä¸ºä¸­æ–‡
        if self.config['text_processing'].get('localize_figures', True):
            text = re.sub(r'Figure\s*(\d+)', r'å›¾\1', text, flags=re.IGNORECASE)
        
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def split_long_text(self, text: str, max_length: int = 500) -> List[str]:
        """å°†é•¿æ–‡æœ¬åˆ†æ®µ"""
        if len(text) <= max_length:
            return [text]
        
        segments = []
        current = ""
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ.!?])', text)
        
        for i in range(0, len(sentences) - 1, 2):
            sentence = sentences[i] + (sentences[i+1] if i+1 < len(sentences) else "")
            
            if len(current) + len(sentence) > max_length:
                if current:
                    segments.append(current.strip())
                current = sentence
            else:
                current += sentence
        
        if current:
            segments.append(current.strip())
        
        return segments


class AudioMerger:
    """éŸ³é¢‘åˆå¹¶å·¥å…·"""
    
    @staticmethod
    def merge_wav_files(file_list: List[str], output_path: str, silence_duration: float = 0.5):
        """
        åˆå¹¶å¤šä¸ª WAV æ–‡ä»¶ï¼Œåœ¨ç‰‡æ®µé—´æ·»åŠ é™éŸ³
        
        Args:
            file_list: WAV æ–‡ä»¶åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            silence_duration: é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        if not file_list:
            return
        
        # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶è·å–å‚æ•°
        with wave.open(file_list[0], 'rb') as wf:
            n_channels = wf.getnchannels()
            sample_width = wf.getsampwidth()
            frame_rate = wf.getframerate()
        
        # ç”Ÿæˆé™éŸ³æ•°æ®
        silence_frames = int(frame_rate * silence_duration)
        silence_data = b'\x00' * (silence_frames * sample_width * n_channels)
        
        # åˆå¹¶æ‰€æœ‰æ–‡ä»¶
        with wave.open(output_path, 'wb') as output:
            output.setnchannels(n_channels)
            output.setsampwidth(sample_width)
            output.setframerate(frame_rate)
            
            for i, file_path in enumerate(file_list):
                with wave.open(file_path, 'rb') as wf:
                    output.writeframes(wf.readframes(wf.getnframes()))
                
                # åœ¨ç‰‡æ®µé—´æ·»åŠ é™éŸ³ï¼ˆæœ€åä¸€ä¸ªé™¤å¤–ï¼‰
                if i < len(file_list) - 1:
                    output.writeframes(silence_data)


class TTSGenerator:
    """è¯­éŸ³åˆæˆä¸»ç±»"""
    
    # æƒ…ç»ªåˆ° TTS å‚æ•°çš„æ˜ å°„
    # ä¸åŒæä¾›å•†æ”¯æŒçš„æƒ…ç»ªå‚æ•°ä¸åŒï¼š
    # - MiniMax: æ”¯æŒ emotion å‚æ•° (happy, sad, angry, fearful, disgusted, surprised, neutral)
    #            åŒæ—¶æ”¯æŒ speed, pitch(æ•´æ•°), vol
    # - Qwen: ä½¿ç”¨ instruction æ–‡æœ¬æè¿°
    # - SiliconFlow: éƒ¨åˆ†æ¨¡å‹ä¸æ”¯æŒ pitch/emotionï¼Œä½¿ç”¨ speed è°ƒèŠ‚
    MOOD_TO_TTS = {
        'gentle': {'speed': 1.0, 'pitch': 0, 'vol': 1.0, 'emotion': 'neutral', 'instruction': 'è¯­é€Ÿé€‚ä¸­ï¼Œè¯­æ°”æ¸©æŸ”å¹³å’Œ'},
        'happy': {'speed': 1.1, 'pitch': 2, 'vol': 1.0, 'emotion': 'happy', 'instruction': 'è¯­é€Ÿç¨å¿«ï¼Œè¯­æ°”è½»å¿«æ„‰æ‚¦'},
        'confident': {'speed': 1.0, 'pitch': 0, 'vol': 1.1, 'emotion': 'neutral', 'instruction': 'è¯­é€Ÿé€‚ä¸­ï¼Œè¯­æ°”åšå®šè‡ªä¿¡'},
        'expectant': {'speed': 1.1, 'pitch': 4, 'vol': 1.0, 'emotion': 'happy', 'instruction': 'è¯­é€Ÿç¨å¿«ï¼Œè¯­æ°”å……æ»¡æœŸå¾…å’Œå¥½å¥‡'},
        'confused': {'speed': 0.9, 'pitch': 2, 'vol': 1.0, 'emotion': 'surprised', 'instruction': 'è¯­é€Ÿç¨æ…¢ï¼Œè¯­æ°”å¸¦æœ‰ç–‘é—®å’Œå›°æƒ‘'},
        'shocked': {'speed': 1.2, 'pitch': 8, 'vol': 1.1, 'emotion': 'surprised', 'instruction': 'è¯­é€Ÿè¾ƒå¿«ï¼Œè¯­æ°”æƒŠè®¶éœ‡æƒŠ'},
        'angry': {'speed': 1.2, 'pitch': -4, 'vol': 1.2, 'emotion': 'angry', 'instruction': 'è¯­é€Ÿè¾ƒå¿«ï¼Œè¯­æ°”æ„¤æ€’ä¸æ»¡'},
        'sad': {'speed': 0.8, 'pitch': -6, 'vol': 0.9, 'emotion': 'sad', 'instruction': 'è¯­é€Ÿè¾ƒæ…¢ï¼Œè¯­æ°”æ‚²ä¼¤ä½æ²‰'},
        'resigned': {'speed': 1.0, 'pitch': -2, 'vol': 1.0, 'emotion': 'sad', 'instruction': 'è¯­é€Ÿé€‚ä¸­ï¼Œè¯­æ°”æ— å¥ˆå¹³æ·¡'},
    }
    
    def __init__(self, config_path: str = "configs/config.yaml"):
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # æ˜¯å¦å¯ç”¨æƒ…ç»ªåŠŸèƒ½ï¼Œé»˜è®¤å¼€å¯
        self.enable_mood = self.config.get('mood', {}).get('enable', True)
        # æ˜¯å¦ä½¿ç”¨ Markdown ä¸­çš„æƒ…ç»ªå‚æ•°ï¼Œé»˜è®¤å¼€å¯
        self.use_emotion = self.config.get('emotion', {}).get('use_emotion', True)
        # é»˜è®¤æƒ…ç»ª
        self.default_emotion = self.config.get('emotion', {}).get('default_emotion', 'gentle')
        # å½“ use_emotion ä¸º false æ—¶ï¼Œæ˜¯å¦ä¼ é€’ speed/pitch/vol å‚æ•°
        self.pass_voice_params = self.config.get('emotion', {}).get('pass_voice_params', False)
        
        if self.enable_mood:
            if self.use_emotion:
                print("âœ¨ æƒ…ç»ªåŠŸèƒ½å·²å¯ç”¨ï¼ˆä½¿ç”¨æ–‡æœ¬æ ‡æ³¨çš„æƒ…ç»ªï¼‰")
            else:
                if self.pass_voice_params:
                    print("âœ¨ æƒ…ç»ªåŠŸèƒ½å·²å¯ç”¨ï¼ˆAPI è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ªï¼Œä¿ç•™éŸ³è‰²å‚æ•°ï¼‰")
                else:
                    print("âœ¨ æƒ…ç»ªåŠŸèƒ½å·²å¯ç”¨ï¼ˆAPI å®Œå…¨è‡ªåŠ¨åˆ¤æ–­ï¼‰")
        else:
            print("â„¹ï¸ æƒ…ç»ªåŠŸèƒ½å·²ç¦ç”¨")
        
        # åˆå§‹åŒ– TTS å®¢æˆ·ç«¯
        provider = self.config.get('provider', 'qwen').lower()
        
        if provider == 'siliconflow':
            self.client = SiliconFlowTTSClient(self.config)
            print(f"ä½¿ç”¨æä¾›å•†: ç¡…åŸºæµåŠ¨ (SiliconFlow) - æ¨¡å‹: {self.config.get('api', {}).get('model', 'IndexTeam/IndexTTS-2')}")
        elif provider == 'qwen':
            self.client = QwenTTSClient(self.config)
            print(f"ä½¿ç”¨æä¾›å•†: é˜¿é‡Œäº‘ç™¾ç‚¼ (Qwen)")
        elif provider == 'minimax':
            self.client = MiniMaxTTSClient(self.config)
            print(f"ä½¿ç”¨æä¾›å•†: MiniMax - æ¨¡å‹: {self.config.get('api', {}).get('model', 'speech-2.6-hd')}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ TTS æä¾›å•†: {provider}ï¼Œè¯·ä½¿ç”¨ 'qwen'ã€'siliconflow' æˆ– 'minimax'")
        
        # åˆå§‹åŒ–å…¶ä»–ç»„ä»¶
        self.parser = MarkdownParser(self.config)
        self.merger = AudioMerger()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        base_output_dir = Path(self.config['output']['output_dir'])
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ—¶é—´ç¼–å·å­æ–‡ä»¶å¤¹
        use_timestamp_subdir = self.config['output'].get('use_timestamp_subdir', False)
        if use_timestamp_subdir:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.output_dir = base_output_dir / timestamp
        else:
            self.output_dir = base_output_dir
        
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
    
    def generate(self, markdown_path: str):
        """
        ç”Ÿæˆè¯­éŸ³
        
        Args:
            markdown_path: Markdown æ–‡ä»¶è·¯å¾„
        """
        print(f"æ­£åœ¨è§£ææ–‡ä»¶: {markdown_path}")
        dialogues = self.parser.parse(markdown_path)
        print(f"å…±è§£æåˆ° {len(dialogues)} æ®µå¯¹è¯")
        
        if not dialogues:
            print("æœªæ‰¾åˆ°å¯¹è¯å†…å®¹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
            return
        
        # æ£€æµ‹æ˜¯å¦ä¸º MOSS-TTSD æ¨¡å‹ï¼ˆåŒäººå¯¹è¯æ¨¡å¼ï¼‰
        if isinstance(self.client, SiliconFlowTTSClient) and self.client.is_moss_model:
            self._generate_moss_dialogue(dialogues)
        else:
            self._generate_standard(dialogues)
    
    def _generate_moss_dialogue(self, dialogues: List[DialogueLine]):
        """
        MOSS-TTSD ä¸“ç”¨ï¼šä¸€æ¬¡æ€§ç”ŸæˆåŒäººå¯¹è¯
        """
        print(f"\nğŸ­ ä½¿ç”¨ MOSS-TTSD åŒäººå¯¹è¯æ¨¡å¼")
        print(f"   å°† {len(dialogues)} æ®µå¯¹è¯ä¸€æ¬¡æ€§åˆæˆ...")
        
        audio_files = []
        failed_count = 0
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        filename = f"{self.config['output']['prefix']}_dialogue_combined.wav"
        output_path = self.output_dir / filename
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if output_path.exists() and output_path.stat().st_size > 0:
            print(f"âœ“ å·²å­˜åœ¨: {filename}")
            audio_files.append(str(output_path))
        else:
            # è·å– male é…ç½®çš„éŸ³è‰²ï¼ˆåŒ…å« referencesï¼‰
            voice_config = self.config['voices']['male']
            
            # ä¸€æ¬¡æ€§åˆæˆæ•´ä¸ªå¯¹è¯
            success = self.client.synthesize_dialogue(dialogues, voice_config, str(output_path))
            
            if success:
                audio_files.append(str(output_path))
            else:
                failed_count += 1
        
        print(f"\n{'='*50}")
        print(f"ç”Ÿæˆå®Œæˆ!")
        print(f"æˆåŠŸ: {len(audio_files)} ä¸ªå¯¹è¯éŸ³é¢‘")
        if failed_count > 0:
            print(f"å¤±è´¥: {failed_count}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
    
    def _generate_standard(self, dialogues: List[DialogueLine]):
        """
        æ ‡å‡†æ¨¡å¼ï¼šé€æ®µåˆæˆè¯­éŸ³
        """
        audio_files = []
        failed_count = 0
        
        # è·å–é€Ÿç‡é™åˆ¶é…ç½®
        rate_limit = self.config.get('rate_limit', {})
        delay = rate_limit.get('delay', 0.3)  # é»˜è®¤ 0.3 ç§’
        max_retries = rate_limit.get('max_retries', 0)
        retry_delay = rate_limit.get('retry_delay', 5.0)
        
        for dialogue in dialogues:
            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"{self.config['output']['prefix']}_{dialogue.index:03d}_{dialogue.speaker}.wav"
            output_path = self.output_dir / filename
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if output_path.exists() and output_path.stat().st_size > 0:
                print(f"[{dialogue.index}/{len(dialogues)}] âœ“ å·²å­˜åœ¨: {filename}")
                audio_files.append(str(output_path))
                continue
            
            print(f"[{dialogue.index}/{len(dialogues)}] {dialogue.speaker}: {dialogue.text[:40]}...")
            
            # è·å–éŸ³è‰²é…ç½®
            voice_config = self.config['voices'][dialogue.speaker].copy()
            
            # å¦‚æœå¯ç”¨æƒ…ç»ªåŠŸèƒ½ï¼Œåº”ç”¨æƒ…ç»ªå‚æ•°
            if self.enable_mood and dialogue.mood in self.MOOD_TO_TTS:
                mood_params = self.MOOD_TO_TTS[dialogue.mood]
                # æ ¹æ®æä¾›å•†åº”ç”¨ä¸åŒçš„å‚æ•°
                provider = self.config.get('provider', 'qwen').lower()
                
                if provider == 'minimax':
                    # MiniMax æ”¯æŒ emotion å‚æ•° (happy, sad, angry, fearful, disgusted, surprised, neutral)
                    # åŒæ—¶æ”¯æŒ speed, pitch(æ•´æ•°), vol
                    if self.use_emotion:
                        # ä½¿ç”¨æ–‡æœ¬æ ‡æ³¨çš„æƒ…ç»ªå‚æ•°
                        voice_config['speed'] = mood_params['speed']
                        voice_config['pitch'] = int(mood_params['pitch'])
                        voice_config['vol'] = mood_params['vol']
                        voice_config['emotion'] = mood_params['emotion']
                        print(f"  [MiniMax æƒ…ç»ª: {mood_params['emotion']}]")
                    else:
                        # ä¸ä¼ é€’æƒ…ç»ªå‚æ•°ï¼Œè®© MiniMax è‡ªåŠ¨åˆ¤æ–­
                        if self.pass_voice_params:
                            # åªä¼ é€’ speed/pitch/volï¼Œè®© API è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ª
                            voice_config['speed'] = mood_params['speed']
                            voice_config['pitch'] = int(mood_params['pitch'])
                            voice_config['vol'] = mood_params['vol']
                            print("  [MiniMax è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ªï¼Œä½¿ç”¨é…ç½®éŸ³è‰²å‚æ•°]")
                        else:
                            # å®Œå…¨ä¸ä¼ é€’æƒ…ç»ªç›¸å…³å‚æ•°ï¼Œè®© API å®Œå…¨è‡ªåŠ¨åˆ¤æ–­
                            print("  [MiniMax å®Œå…¨è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ªå’ŒéŸ³è‰²]")
                elif provider == 'siliconflow':
                    # SiliconFlow ä¸åŒæ¨¡å‹æ”¯æŒä¸åŒçš„æƒ…ç»ªå‚æ•°
                    model = self.config.get('api', {}).get('model', '')
                    
                    if self.use_emotion:
                        # IndexTTS2 æ”¯æŒ emo_vector ç­‰æƒ…ç»ªå‚æ•°
                        if 'IndexTTS' in model:
                            # IndexTTS2 æƒ…ç»ªæ˜ å°„
                            indextts_emotion = SiliconFlowTTSClient.MOOD_TO_INDEXTTS.get(dialogue.mood, 'Neutral')
                            voice_config['emo_vector'] = indextts_emotion
                            # æƒ…æ„Ÿå¼ºåº¦ (0.0 ~ 1.0)
                            voice_config['emo_alpha'] = 0.7
                            # è¯­é€Ÿ
                            voice_config['speed'] = mood_params['speed']
                            print(f"  [IndexTTS2 æƒ…ç»ª: {indextts_emotion}]")
                        else:
                            # å…¶ä»–æ¨¡å‹ä»…ä½¿ç”¨ speed
                            voice_config['speed'] = mood_params['speed']
                    else:
                        if self.pass_voice_params:
                            # åªä¼ é€’ speedï¼Œè®© API è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ª
                            voice_config['speed'] = mood_params['speed']
                            print("  [SiliconFlow è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ªï¼Œä½¿ç”¨é…ç½®è¯­é€Ÿ]")
                        else:
                            print("  [SiliconFlow å®Œå…¨è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ªå’ŒéŸ³è‰²]")
                elif provider == 'qwen':
                    # Qwen ä½¿ç”¨ instructions æ§åˆ¶é£æ ¼
                    if self.use_emotion:
                        if 'instructions' in voice_config:
                            # åœ¨åŸæœ‰æŒ‡ä»¤åŸºç¡€ä¸Šæ·»åŠ æƒ…ç»ªæè¿°
                            base_instruction = voice_config['instructions']
                            voice_config['instructions'] = f"{base_instruction}ï¼Œ{mood_params['instruction']}"
                        else:
                            voice_config['instructions'] = mood_params['instruction']
                        # æ ‡è®°éœ€è¦ä¼˜åŒ–æŒ‡ä»¤
                        voice_config['optimize_instructions'] = True
                        print(f"  [Qwen æƒ…ç»ª: {dialogue.mood}]")
                    else:
                        if self.pass_voice_params and 'instructions' in voice_config:
                            # ä¿ç•™åŸæœ‰æŒ‡ä»¤ï¼Œä¸æ·»åŠ æƒ…ç»ªæè¿°
                            print("  [Qwen è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ªï¼Œä½¿ç”¨é…ç½®éŸ³è‰²]")
                        else:
                            # æ¸…é™¤æŒ‡ä»¤ï¼Œè®© API å®Œå…¨è‡ªåŠ¨åˆ¤æ–­
                            if 'instructions' in voice_config:
                                del voice_config['instructions']
                            print("  [Qwen å®Œå…¨è‡ªåŠ¨åˆ¤æ–­æƒ…ç»ªå’ŒéŸ³è‰²]")
            
            # åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬
            max_length = self.config['text_processing'].get('max_text_length', 500)
            segments = self.parser.split_long_text(dialogue.text, max_length)
            
            segment_files = []
            for seg_idx, segment in enumerate(segments):
                if len(segments) == 1:
                    seg_filename = filename
                else:
                    seg_filename = f"{self.config['output']['prefix']}_{dialogue.index:03d}_{dialogue.speaker}_part{seg_idx+1}.wav"
                
                seg_path = self.output_dir / seg_filename
                
                # åˆæˆè¯­éŸ³ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
                success = False
                retries = 0
                while not success and retries <= max_retries:
                    if retries > 0:
                        wait_time = retry_delay * retries
                        print(f"  ç­‰å¾… {wait_time:.0f} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                    
                    success = self.client.synthesize(segment, voice_config, str(seg_path))
                    
                    if not success and retries < max_retries:
                        retries += 1
                    else:
                        break
                
                if success:
                    segment_files.append(str(seg_path))
                    # è¯·æ±‚é—´éš”å»¶è¿Ÿï¼ˆé¿å…è§¦å‘ rate limitï¼‰
                    time.sleep(delay)
                else:
                    failed_count += 1
            
            # åˆå¹¶åˆ†æ®µ
            if len(segment_files) > 1:
                merged_path = self.output_dir / filename
                self.merger.merge_wav_files(segment_files, str(merged_path), silence_duration=0.2)
                audio_files.append(str(merged_path))
                # åˆ é™¤ä¸´æ—¶åˆ†æ®µæ–‡ä»¶
                for f in segment_files:
                    if os.path.exists(f):
                        os.remove(f)
            elif segment_files:
                audio_files.append(segment_files[0])
                print(f"  âœ“ å·²ç”Ÿæˆ: {filename}")
            else:
                failed_count += 1
                print(f"  âœ— ç”Ÿæˆå¤±è´¥")
        
        print(f"\n{'='*50}")
        print(f"ç”Ÿæˆå®Œæˆ!")
        print(f"æˆåŠŸ: {len(audio_files)} æ®µ")
        print(f"å¤±è´¥: {failed_count} æ®µ")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
        
        # åˆå¹¶æ‰€æœ‰éŸ³é¢‘
        if self.config['output'].get('merge_audio', True) and len(audio_files) > 1:
            final_path = self.output_dir / f"{self.config['output']['prefix']}_complete.wav"
            if final_path.exists():
                print(f"åˆå¹¶æ–‡ä»¶å·²å­˜åœ¨: {final_path.name}")
            else:
                print("æ­£åœ¨åˆå¹¶æ‰€æœ‰éŸ³é¢‘...")
                silence = self.config['output'].get('silence_between', 0.5)
                self.merger.merge_wav_files(audio_files, str(final_path), silence)
                print(f"åˆå¹¶å®Œæˆ: {final_path.name}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='TTS è¯­éŸ³åˆæˆå·¥å…· - å°† Markdown å¯¹è¯è½¬æ¢ä¸ºè¯­éŸ³',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨
  python tts_generator.py æ–‡çŒ®è§£è¯»å¯¹è¯æ–‡æ¡ˆ-2.md
  
  # æŒ‡å®šè‡ªå®šä¹‰é…ç½®
  python tts_generator.py æ–‡çŒ®.md -c my_config.yaml
  
  # æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶
  for f in *.md; do python tts_generator.py "$f"; done

æ”¯æŒçš„ TTS æä¾›å•†:
  â€¢ qwen         - é˜¿é‡Œäº‘ç™¾ç‚¼ Qwen-TTS
  â€¢ siliconflow  - ç¡…åŸºæµåŠ¨ SiliconFlow (æ”¯æŒ IndexTTS2, CosyVoice2-0.5B, MOSS-TTSD ç­‰)
  â€¢ minimax      - MiniMax Speech (æ”¯æŒ speech-2.6-hd, speech-2.6-turbo ç­‰)

ç›¸å…³è„šæœ¬:
  tts_batch.py          - åˆ†æ‰¹ç”Ÿæˆï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
  video_generator.py    - å°†ç”Ÿæˆçš„éŸ³é¢‘è½¬æ¢ä¸ºè§†é¢‘æ’­å®¢
        """
    )
    
    parser.add_argument(
        'input', 
        nargs='?', 
        default='ADAR1æ–‡çŒ®è§£è¯»å¯¹è¯æ–‡æ¡ˆ.md',
        help='è¾“å…¥çš„ Markdown æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ADAR1æ–‡çŒ®è§£è¯»å¯¹è¯æ–‡æ¡ˆ.md)'
    )
    parser.add_argument(
        '-c', '--config', 
        default='configs/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: configs/config.yaml)'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ '{args.input}'")
        return
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(args.config):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ '{args.config}'")
        return
    
    # ç”Ÿæˆè¯­éŸ³
    try:
        generator = TTSGenerator(args.config)
        generator.generate(args.input)
    except ValueError as e:
        print(f"é…ç½®é”™è¯¯: {e}")
    except Exception as e:
        print(f"è¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
